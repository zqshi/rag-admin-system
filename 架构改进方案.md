# RAG系统架构改进方案

**版本**: 2.0  
**日期**: 2025年8月12日  
**状态**: 架构评审

---

## 一、向量索引版本管理改进

### 1.1 问题分析
当前系统缺乏向量索引版本管理，导致：
- Embedding模型升级后无法区分新旧索引
- 无法实现灰度切换和回滚
- 索引质量评估困难

### 1.2 架构设计

```python
# 向量索引版本管理器
class VectorIndexVersionManager:
    """
    向量索引版本管理核心组件
    支持多版本并存、灰度切换、自动迁移
    """
    
    def __init__(self):
        self.versions = {}
        self.active_version = None
        self.migration_queue = asyncio.Queue()
    
    async def create_version(
        self, 
        version_name: str,
        embedding_model: str,
        dimension: int,
        metadata: dict
    ) -> IndexVersion:
        """创建新的索引版本"""
        version = IndexVersion(
            id=f"v_{int(time.time())}",
            name=version_name,
            model=embedding_model,
            dimension=dimension,
            created_at=datetime.now(),
            status="building",
            metadata=metadata
        )
        
        # 创建独立的向量索引集合
        await self.vector_db.create_collection(
            name=f"index_{version.id}",
            dimension=dimension,
            index_type="HNSW",
            metric_type="IP"
        )
        
        self.versions[version.id] = version
        return version
    
    async def migrate_index(
        self,
        source_version: str,
        target_version: str,
        batch_size: int = 1000
    ):
        """索引迁移任务"""
        migration_task = MigrationTask(
            source=source_version,
            target=target_version,
            total_docs=await self.count_docs(source_version),
            processed=0,
            status="running"
        )
        
        async for batch in self.iter_batches(source_version, batch_size):
            # 使用新模型重新生成向量
            new_embeddings = await self.generate_embeddings(
                texts=batch.texts,
                model=self.versions[target_version].model
            )
            
            # 写入新版本索引
            await self.vector_db.insert(
                collection=f"index_{target_version}",
                embeddings=new_embeddings,
                metadata=batch.metadata
            )
            
            migration_task.processed += len(batch)
            await self.publish_progress(migration_task)
    
    async def switch_version(
        self,
        target_version: str,
        traffic_percentage: float = 0.1
    ):
        """灰度切换索引版本"""
        # 配置灰度规则
        gray_rule = GrayScaleRule(
            version=target_version,
            percentage=traffic_percentage,
            user_whitelist=[],  # 可配置白名单用户
            start_time=datetime.now()
        )
        
        # 更新路由配置
        await self.update_routing_rules(gray_rule)
        
        # 监控切换效果
        await self.monitor_version_performance(
            old_version=self.active_version,
            new_version=target_version,
            metrics=["latency", "recall", "precision"]
        )
```

### 1.3 数据模型设计

```sql
-- 索引版本管理表
CREATE TABLE `vector_index_versions` (
    `version_id` VARCHAR(64) PRIMARY KEY,
    `version_name` VARCHAR(128) NOT NULL,
    `embedding_model` VARCHAR(128) NOT NULL,
    `dimension` INT NOT NULL,
    `total_documents` BIGINT DEFAULT 0,
    `index_size_mb` DECIMAL(10,2),
    `status` ENUM('building','ready','migrating','deprecated') DEFAULT 'building',
    `quality_score` DECIMAL(3,2) COMMENT '索引质量评分',
    `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    `activated_at` TIMESTAMP NULL,
    `deprecated_at` TIMESTAMP NULL,
    
    INDEX idx_status (status),
    INDEX idx_model (embedding_model)
) ENGINE=InnoDB;

-- 索引迁移任务表
CREATE TABLE `index_migration_tasks` (
    `task_id` BIGINT PRIMARY KEY AUTO_INCREMENT,
    `source_version` VARCHAR(64) NOT NULL,
    `target_version` VARCHAR(64) NOT NULL,
    `total_documents` BIGINT NOT NULL,
    `processed_documents` BIGINT DEFAULT 0,
    `status` ENUM('pending','running','completed','failed') DEFAULT 'pending',
    `error_message` TEXT,
    `started_at` TIMESTAMP NULL,
    `completed_at` TIMESTAMP NULL,
    
    FOREIGN KEY (source_version) REFERENCES vector_index_versions(version_id),
    FOREIGN KEY (target_version) REFERENCES vector_index_versions(version_id)
) ENGINE=InnoDB;
```

---

## 二、多模态RAG支持

### 2.1 架构扩展

```python
# 多模态处理Pipeline
class MultiModalProcessor:
    """
    统一的多模态数据处理框架
    支持文本、图片、表格、音视频等多种模态
    """
    
    def __init__(self):
        self.processors = {
            'text': TextProcessor(),
            'image': ImageProcessor(),
            'table': TableProcessor(),
            'audio': AudioProcessor(),
            'video': VideoProcessor()
        }
        
        # 多模态融合模型
        self.fusion_model = MultiModalFusionModel()
    
    async def process_document(self, document: Document) -> ProcessedDocument:
        """统一的文档处理入口"""
        # 1. 模态检测
        modalities = await self.detect_modalities(document)
        
        # 2. 并行处理各模态
        tasks = []
        for modality in modalities:
            processor = self.processors[modality.type]
            tasks.append(processor.process(modality.content))
        
        processed_parts = await asyncio.gather(*tasks)
        
        # 3. 多模态融合
        fused_result = await self.fusion_model.fuse(processed_parts)
        
        return ProcessedDocument(
            doc_id=document.id,
            modalities=modalities,
            embeddings=fused_result.embeddings,
            metadata=fused_result.metadata
        )


class ImageProcessor:
    """图片处理器"""
    
    def __init__(self):
        self.ocr_engine = OCREngine()  # OCR识别
        self.vision_model = VisionModel()  # 视觉理解模型
        self.caption_model = CaptionModel()  # 图片描述生成
    
    async def process(self, image_data: bytes) -> ImageProcessResult:
        # 1. OCR文字提取
        ocr_text = await self.ocr_engine.extract_text(image_data)
        
        # 2. 视觉特征提取
        visual_features = await self.vision_model.extract_features(image_data)
        
        # 3. 生成图片描述
        caption = await self.caption_model.generate_caption(image_data)
        
        # 4. 生成统一向量表示
        combined_text = f"{caption}\n{ocr_text}"
        embedding = await self.generate_embedding(combined_text)
        
        return ImageProcessResult(
            text=ocr_text,
            caption=caption,
            visual_features=visual_features,
            embedding=embedding
        )


class TableProcessor:
    """表格处理器"""
    
    async def process(self, table_data: pd.DataFrame) -> TableProcessResult:
        # 1. 表格结构化分析
        schema = self.analyze_schema(table_data)
        
        # 2. 生成表格摘要
        summary = await self.generate_table_summary(table_data)
        
        # 3. 关键信息提取
        key_insights = await self.extract_insights(table_data)
        
        # 4. 转换为向量
        table_text = self.table_to_text(table_data, schema)
        embedding = await self.generate_embedding(table_text)
        
        return TableProcessResult(
            schema=schema,
            summary=summary,
            insights=key_insights,
            embedding=embedding,
            structured_data=table_data.to_dict()
        )
```

### 2.2 存储架构

```yaml
# 多模态数据存储配置
storage_config:
  text:
    backend: elasticsearch
    index_settings:
      analyzer: ik_max_word
      
  image:
    backend: minio
    processing:
      thumbnail_sizes: [128, 256, 512]
      formats: [webp, jpg]
    vector_index: milvus
    
  table:
    backend: clickhouse
    schema:
      dynamic_columns: true
      compression: lz4
      
  audio:
    backend: s3
    transcription:
      model: whisper-large-v3
      languages: [zh, en]
      
  video:
    backend: cdn
    processing:
      keyframe_extraction: true
      subtitle_generation: true
```

---

## 三、实时协作冲突处理

### 3.1 分布式锁机制

```python
# 协作锁管理器
class CollaborationLockManager:
    """
    基于Redis的分布式锁实现
    支持细粒度锁和自动释放
    """
    
    def __init__(self, redis_client):
        self.redis = redis_client
        self.locks = {}
    
    async def acquire_lock(
        self,
        resource_type: str,
        resource_id: str,
        user_id: str,
        ttl: int = 300  # 5分钟自动释放
    ) -> Optional[Lock]:
        """获取资源锁"""
        lock_key = f"lock:{resource_type}:{resource_id}"
        lock_value = f"{user_id}:{uuid.uuid4()}"
        
        # 使用Lua脚本保证原子性
        lua_script = """
        local key = KEYS[1]
        local value = ARGV[1]
        local ttl = ARGV[2]
        
        if redis.call('exists', key) == 0 then
            redis.call('set', key, value, 'EX', ttl)
            return 1
        else
            return 0
        end
        """
        
        acquired = await self.redis.eval(
            lua_script,
            keys=[lock_key],
            args=[lock_value, ttl]
        )
        
        if acquired:
            lock = Lock(
                key=lock_key,
                value=lock_value,
                owner=user_id,
                acquired_at=datetime.now(),
                ttl=ttl
            )
            self.locks[lock_key] = lock
            
            # 发送锁定通知
            await self.notify_lock_acquired(resource_type, resource_id, user_id)
            
            return lock
        
        return None
    
    async def release_lock(self, lock: Lock) -> bool:
        """释放锁"""
        # 只有锁的持有者才能释放
        lua_script = """
        local key = KEYS[1]
        local value = ARGV[1]
        
        if redis.call('get', key) == value then
            redis.call('del', key)
            return 1
        else
            return 0
        end
        """
        
        released = await self.redis.eval(
            lua_script,
            keys=[lock.key],
            args=[lock.value]
        )
        
        if released:
            del self.locks[lock.key]
            await self.notify_lock_released(lock)
        
        return bool(released)


# 实时协作管理器
class RealTimeCollaborationManager:
    """
    实时协作核心组件
    基于WebSocket实现多用户协同编辑
    """
    
    def __init__(self):
        self.lock_manager = CollaborationLockManager()
        self.conflict_resolver = ConflictResolver()
        self.operation_log = OperationLog()
    
    async def handle_edit_request(
        self,
        user_id: str,
        resource_id: str,
        operation: EditOperation
    ) -> EditResult:
        """处理编辑请求"""
        
        # 1. 尝试获取锁
        lock = await self.lock_manager.acquire_lock(
            resource_type="document",
            resource_id=resource_id,
            user_id=user_id
        )
        
        if not lock:
            # 2. 锁获取失败，进入冲突处理
            return await self.handle_conflict(
                user_id=user_id,
                resource_id=resource_id,
                operation=operation
            )
        
        try:
            # 3. 执行编辑操作
            result = await self.apply_operation(operation)
            
            # 4. 记录操作日志（用于CRDT）
            await self.operation_log.append(
                user_id=user_id,
                resource_id=resource_id,
                operation=operation,
                timestamp=datetime.now()
            )
            
            # 5. 广播变更
            await self.broadcast_changes(
                resource_id=resource_id,
                changes=result.changes,
                exclude_user=user_id
            )
            
            return result
            
        finally:
            # 6. 释放锁
            await self.lock_manager.release_lock(lock)
    
    async def handle_conflict(
        self,
        user_id: str,
        resource_id: str,
        operation: EditOperation
    ) -> EditResult:
        """冲突处理策略"""
        
        # 获取当前锁持有者
        current_lock = await self.lock_manager.get_lock_info(resource_id)
        
        # 策略1：操作转换（OT）
        if operation.is_transformable():
            transformed_op = await self.conflict_resolver.transform(
                operation=operation,
                against=current_lock.pending_operations
            )
            
            # 将转换后的操作加入队列
            await self.queue_operation(transformed_op)
            
            return EditResult(
                status="queued",
                message=f"操作已排队，当前编辑者：{current_lock.owner}"
            )
        
        # 策略2：三路合并
        elif operation.is_mergeable():
            merge_result = await self.conflict_resolver.three_way_merge(
                base=await self.get_base_version(resource_id),
                theirs=await self.get_current_version(resource_id),
                yours=operation.apply_to(await self.get_base_version(resource_id))
            )
            
            if merge_result.has_conflicts:
                return EditResult(
                    status="conflict",
                    conflicts=merge_result.conflicts,
                    message="存在冲突需要手动解决"
                )
            
            return EditResult(
                status="merged",
                changes=merge_result.merged_changes
            )
        
        # 策略3：拒绝操作
        else:
            return EditResult(
                status="rejected",
                message=f"资源正被{current_lock.owner}编辑，请稍后重试"
            )
```

---

## 四、数据版本控制

### 4.1 Git-like版本管理

```python
# 文档版本控制系统
class DocumentVersionControl:
    """
    类Git的文档版本管理
    支持完整的版本历史、分支、合并
    """
    
    def __init__(self):
        self.storage = VersionStorage()
        self.diff_engine = DiffEngine()
        
    async def commit(
        self,
        doc_id: str,
        content: str,
        author: str,
        message: str,
        parent_commit: Optional[str] = None
    ) -> Commit:
        """创建新的提交"""
        
        # 1. 计算内容差异
        if parent_commit:
            parent_content = await self.storage.get_content(parent_commit)
            diff = self.diff_engine.compute_diff(parent_content, content)
        else:
            diff = DiffResult(additions=content, deletions="")
        
        # 2. 创建提交对象
        commit = Commit(
            id=self.generate_commit_hash(content, author, message),
            doc_id=doc_id,
            parent=parent_commit,
            author=author,
            message=message,
            timestamp=datetime.now(),
            diff=diff,
            content_hash=hashlib.sha256(content.encode()).hexdigest()
        )
        
        # 3. 存储提交
        await self.storage.save_commit(commit)
        
        # 4. 更新HEAD指针
        await self.storage.update_head(doc_id, commit.id)
        
        # 5. 触发钩子
        await self.trigger_hooks('post-commit', commit)
        
        return commit
    
    async def checkout(
        self,
        doc_id: str,
        commit_id: str
    ) -> Document:
        """检出特定版本"""
        
        # 1. 获取提交链
        commits = await self.get_commit_chain(doc_id, commit_id)
        
        # 2. 重建文档内容
        content = ""
        for commit in commits:
            content = self.diff_engine.apply_diff(content, commit.diff)
        
        # 3. 返回重建的文档
        return Document(
            id=doc_id,
            content=content,
            version=commit_id,
            metadata=await self.get_metadata(doc_id, commit_id)
        )
    
    async def merge(
        self,
        doc_id: str,
        source_branch: str,
        target_branch: str,
        strategy: MergeStrategy = MergeStrategy.THREE_WAY
    ) -> MergeResult:
        """分支合并"""
        
        # 1. 找到共同祖先
        common_ancestor = await self.find_common_ancestor(
            source_branch,
            target_branch
        )
        
        # 2. 获取三个版本的内容
        base = await self.checkout(doc_id, common_ancestor)
        source = await self.checkout(doc_id, source_branch)
        target = await self.checkout(doc_id, target_branch)
        
        # 3. 执行三路合并
        if strategy == MergeStrategy.THREE_WAY:
            merge_result = await self.three_way_merge(
                base=base.content,
                source=source.content,
                target=target.content
            )
        elif strategy == MergeStrategy.OURS:
            merge_result = MergeResult(content=source.content)
        elif strategy == MergeStrategy.THEIRS:
            merge_result = MergeResult(content=target.content)
        
        # 4. 创建合并提交
        if not merge_result.has_conflicts:
            merge_commit = await self.commit(
                doc_id=doc_id,
                content=merge_result.content,
                author="system",
                message=f"Merge {source_branch} into {target_branch}",
                parent_commit=target_branch
            )
            
            return MergeResult(
                success=True,
                commit_id=merge_commit.id,
                content=merge_result.content
            )
        
        return MergeResult(
            success=False,
            conflicts=merge_result.conflicts
        )
    
    async def diff(
        self,
        doc_id: str,
        from_version: str,
        to_version: str
    ) -> DiffResult:
        """比较两个版本的差异"""
        
        from_doc = await self.checkout(doc_id, from_version)
        to_doc = await self.checkout(doc_id, to_version)
        
        return self.diff_engine.compute_diff(
            from_doc.content,
            to_doc.content,
            algorithm="myers"  # Myers差异算法
        )
```

### 4.2 数据模型

```sql
-- 版本提交表
CREATE TABLE `document_commits` (
    `commit_id` CHAR(40) PRIMARY KEY,  -- SHA-1 hash
    `doc_id` BIGINT NOT NULL,
    `parent_commit` CHAR(40),
    `author` VARCHAR(128) NOT NULL,
    `message` TEXT NOT NULL,
    `content_hash` CHAR(64) NOT NULL,
    `diff_data` MEDIUMBLOB,  -- 压缩的差异数据
    `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_doc (doc_id),
    INDEX idx_parent (parent_commit),
    INDEX idx_author (author),
    FOREIGN KEY (parent_commit) REFERENCES document_commits(commit_id)
) ENGINE=InnoDB;

-- 分支管理表
CREATE TABLE `document_branches` (
    `branch_id` BIGINT PRIMARY KEY AUTO_INCREMENT,
    `doc_id` BIGINT NOT NULL,
    `branch_name` VARCHAR(128) NOT NULL,
    `head_commit` CHAR(40) NOT NULL,
    `created_by` VARCHAR(128) NOT NULL,
    `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    `updated_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_doc_branch (doc_id, branch_name),
    FOREIGN KEY (head_commit) REFERENCES document_commits(commit_id)
) ENGINE=InnoDB;

-- 标签表
CREATE TABLE `document_tags` (
    `tag_id` BIGINT PRIMARY KEY AUTO_INCREMENT,
    `doc_id` BIGINT NOT NULL,
    `tag_name` VARCHAR(128) NOT NULL,
    `commit_id` CHAR(40) NOT NULL,
    `tagger` VARCHAR(128) NOT NULL,
    `message` TEXT,
    `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_doc_tag (doc_id, tag_name),
    FOREIGN KEY (commit_id) REFERENCES document_commits(commit_id)
) ENGINE=InnoDB;
```

---

## 五、成本控制机制

### 5.1 预算管理系统

```python
# Token预算控制器
class TokenBudgetController:
    """
    精细化的Token消耗控制
    支持多维度预算管理和实时监控
    """
    
    def __init__(self):
        self.budgets = {}
        self.usage_tracker = UsageTracker()
        self.alert_manager = AlertManager()
    
    async def create_budget(
        self,
        budget_id: str,
        config: BudgetConfig
    ) -> Budget:
        """创建预算配置"""
        budget = Budget(
            id=budget_id,
            daily_limit=config.daily_limit,
            monthly_limit=config.monthly_limit,
            cost_limit_usd=config.cost_limit_usd,
            
            # 分层预算
            user_quotas=config.user_quotas,
            department_quotas=config.department_quotas,
            api_quotas=config.api_quotas,
            
            # 预警阈值
            warning_threshold=config.warning_threshold or 0.8,
            critical_threshold=config.critical_threshold or 0.95,
            
            # 策略配置
            overflow_strategy=config.overflow_strategy,  # reject/queue/degrade
            priority_rules=config.priority_rules
        )
        
        self.budgets[budget_id] = budget
        
        # 启动监控任务
        asyncio.create_task(self.monitor_budget(budget))
        
        return budget
    
    async def check_and_consume(
        self,
        request: TokenRequest
    ) -> TokenConsumptionResult:
        """检查并消费Token预算"""
        
        # 1. 获取适用的预算
        budget = self.get_applicable_budget(request)
        
        # 2. 预估Token消耗
        estimated_tokens = await self.estimate_tokens(request)
        estimated_cost = self.calculate_cost(
            tokens=estimated_tokens,
            model=request.model
        )
        
        # 3. 检查预算
        budget_check = await self.check_budget_availability(
            budget=budget,
            user_id=request.user_id,
            tokens=estimated_tokens,
            cost=estimated_cost
        )
        
        if not budget_check.allowed:
            # 4. 预算不足处理
            return await self.handle_budget_exceeded(
                request=request,
                budget=budget,
                reason=budget_check.reason
            )
        
        # 5. 记录消耗（预扣）
        consumption_id = await self.usage_tracker.record_consumption(
            user_id=request.user_id,
            tokens=estimated_tokens,
            cost=estimated_cost,
            status="pending"
        )
        
        # 6. 执行请求
        try:
            result = await self.execute_request(request)
            
            # 7. 更新实际消耗
            actual_tokens = result.usage.total_tokens
            actual_cost = self.calculate_cost(actual_tokens, request.model)
            
            await self.usage_tracker.update_consumption(
                consumption_id=consumption_id,
                actual_tokens=actual_tokens,
                actual_cost=actual_cost,
                status="completed"
            )
            
            # 8. 检查预警
            await self.check_alerts(budget, request.user_id)
            
            return TokenConsumptionResult(
                success=True,
                tokens_used=actual_tokens,
                cost_usd=actual_cost,
                remaining_budget=await self.get_remaining_budget(
                    budget,
                    request.user_id
                )
            )
            
        except Exception as e:
            # 回滚预扣
            await self.usage_tracker.rollback_consumption(consumption_id)
            raise
    
    async def handle_budget_exceeded(
        self,
        request: TokenRequest,
        budget: Budget,
        reason: str
    ) -> TokenConsumptionResult:
        """预算超支处理"""
        
        strategy = budget.overflow_strategy
        
        if strategy == "reject":
            # 直接拒绝
            return TokenConsumptionResult(
                success=False,
                error=f"Budget exceeded: {reason}",
                suggestion="请联系管理员提升额度"
            )
            
        elif strategy == "queue":
            # 加入队列等待
            queue_position = await self.queue_request(request)
            return TokenConsumptionResult(
                success=False,
                queued=True,
                queue_position=queue_position,
                estimated_wait_time=self.estimate_wait_time(queue_position)
            )
            
        elif strategy == "degrade":
            # 降级处理
            degraded_request = self.degrade_request(request)
            if self.can_afford(degraded_request, budget):
                return await self.check_and_consume(degraded_request)
            else:
                return TokenConsumptionResult(
                    success=False,
                    error="即使降级也超出预算"
                )
    
    def degrade_request(self, request: TokenRequest) -> TokenRequest:
        """请求降级策略"""
        degraded = request.copy()
        
        # 使用更便宜的模型
        if request.model == "gpt-4":
            degraded.model = "gpt-3.5-turbo"
        elif request.model == "claude-3-opus":
            degraded.model = "claude-3-sonnet"
        
        # 减少token数量
        degraded.max_tokens = min(request.max_tokens * 0.5, 1000)
        
        # 降低温度
        degraded.temperature = 0
        
        return degraded


# 成本优化器
class CostOptimizer:
    """
    智能成本优化组件
    """
    
    async def optimize_request(
        self,
        request: Request,
        context: Context
    ) -> OptimizedRequest:
        """优化请求以降低成本"""
        
        # 1. 缓存检查
        if cached := await self.check_cache(request):
            return OptimizedRequest(
                use_cache=True,
                cached_response=cached,
                estimated_savings=self.calculate_cost(request)
            )
        
        # 2. 模型路由
        best_model = await self.select_model(
            task_type=request.task_type,
            complexity=await self.estimate_complexity(request),
            budget_remaining=context.budget_remaining
        )
        
        # 3. Prompt优化
        optimized_prompt = await self.optimize_prompt(
            original=request.prompt,
            strategy="compression"  # 压缩冗余
        )
        
        # 4. 批处理合并
        if self.can_batch(request):
            batch_id = await self.add_to_batch(request)
            return OptimizedRequest(
                batched=True,
                batch_id=batch_id,
                estimated_wait=self.estimate_batch_wait()
            )
        
        return OptimizedRequest(
            model=best_model,
            prompt=optimized_prompt,
            estimated_cost=self.calculate_cost(best_model, optimized_prompt)
        )
```

### 5.2 成本监控Dashboard配置

```yaml
# 成本监控指标配置
cost_monitoring:
  metrics:
    - name: token_usage_by_user
      type: counter
      labels: [user_id, model, endpoint]
      
    - name: cost_by_department
      type: gauge
      labels: [department, period]
      
    - name: budget_utilization
      type: histogram
      buckets: [0.25, 0.5, 0.75, 0.9, 0.95, 1.0]
      
  alerts:
    - name: budget_warning
      condition: budget_utilization > 0.8
      severity: warning
      channels: [email, slack]
      
    - name: budget_critical
      condition: budget_utilization > 0.95
      severity: critical
      channels: [email, sms, pagerduty]
      
    - name: anomaly_detection
      condition: cost_spike > 3 * moving_average
      severity: warning
      
  dashboards:
    - name: cost_overview
      panels:
        - title: "Token消耗趋势"
          query: "sum(rate(token_usage[5m])) by (model)"
          
        - title: "成本分布"
          query: "sum(cost_by_department) by (department)"
          
        - title: "预算使用率"
          query: "budget_utilization"
          
        - title: "Top 10消耗用户"
          query: "topk(10, sum(token_usage_by_user) by (user_id))"
```

### 5.3 数据库模型

```sql
-- Token使用记录表
CREATE TABLE `token_usage_records` (
    `record_id` BIGINT PRIMARY KEY AUTO_INCREMENT,
    `user_id` VARCHAR(128) NOT NULL,
    `department_id` VARCHAR(64),
    `model` VARCHAR(64) NOT NULL,
    `endpoint` VARCHAR(128),
    `prompt_tokens` INT NOT NULL,
    `completion_tokens` INT NOT NULL,
    `total_tokens` INT NOT NULL,
    `cost_usd` DECIMAL(10,6) NOT NULL,
    `request_id` VARCHAR(128),
    `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_user_time (user_id, created_at),
    INDEX idx_dept_time (department_id, created_at),
    INDEX idx_model (model)
) ENGINE=InnoDB
PARTITION BY RANGE (TO_DAYS(created_at)) (
    PARTITION p_202501 VALUES LESS THAN (TO_DAYS('2025-02-01')),
    PARTITION p_202502 VALUES LESS THAN (TO_DAYS('2025-03-01'))
);

-- 预算配置表
CREATE TABLE `budget_configs` (
    `budget_id` VARCHAR(64) PRIMARY KEY,
    `scope_type` ENUM('global','department','user','api') NOT NULL,
    `scope_id` VARCHAR(128) NOT NULL,
    `daily_limit_tokens` BIGINT,
    `monthly_limit_tokens` BIGINT,
    `daily_limit_usd` DECIMAL(10,2),
    `monthly_limit_usd` DECIMAL(10,2),
    `warning_threshold` DECIMAL(3,2) DEFAULT 0.80,
    `critical_threshold` DECIMAL(3,2) DEFAULT 0.95,
    `overflow_strategy` ENUM('reject','queue','degrade') DEFAULT 'reject',
    `priority` INT DEFAULT 0,
    `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    `updated_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_scope (scope_type, scope_id)
) ENGINE=InnoDB;

-- 成本优化建议表
CREATE TABLE `cost_optimization_suggestions` (
    `suggestion_id` BIGINT PRIMARY KEY AUTO_INCREMENT,
    `user_id` VARCHAR(128),
    `suggestion_type` ENUM('cache','model_switch','batch','prompt_optimize') NOT NULL,
    `description` TEXT NOT NULL,
    `potential_savings_usd` DECIMAL(10,2),
    `implementation_effort` ENUM('low','medium','high'),
    `status` ENUM('pending','accepted','rejected','implemented') DEFAULT 'pending',
    `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_user_status (user_id, status)
) ENGINE=InnoDB;
```

---

## 六、实施优先级和路线图

### Phase 1: 基础架构改进（4周）
1. **向量索引版本管理** - 优先级：高
   - 实现多版本索引并存
   - 灰度切换机制
   - 自动迁移工具

2. **数据版本控制** - 优先级：高
   - Git-like版本管理
   - 差异计算和存储
   - 版本回滚能力

### Phase 2: 功能扩展（6周）
3. **多模态RAG支持** - 优先级：中
   - 图片OCR和理解
   - 表格结构化处理
   - 音视频转写

4. **成本控制机制** - 优先级：高
   - Token预算管理
   - 实时监控告警
   - 成本优化建议

### Phase 3: 协作增强（4周）
5. **实时协作冲突处理** - 优先级：中
   - 分布式锁实现
   - 冲突检测和解决
   - 操作日志审计

---

## 七、架构评估

### 架构影响评估：**高**

### 模式合规性检查
✅ 单一职责原则：每个组件职责明确  
✅ 开闭原则：通过接口和抽象类扩展  
✅ 依赖倒置：依赖抽象而非具体实现  
✅ 接口隔离：细粒度接口设计  
✅ 里氏替换：子类可替换父类  

### 架构改进收益
1. **可维护性提升**：版本管理让系统更易维护
2. **扩展性增强**：多模态支持提升系统能力边界  
3. **可靠性保障**：冲突处理机制确保数据一致性
4. **成本可控**：精细化预算管理降低运营成本
5. **用户体验**：实时协作提升团队效率

### 潜在风险
1. **复杂度增加**：需要更多运维投入
2. **性能开销**：版本管理带来存储压力
3. **迁移成本**：现有数据需要迁移